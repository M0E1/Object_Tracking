import cv2
import streamlit as st
import numpy as np
import tempfile
import time

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Object Tracking App", layout="centered")
st.title('ğŸ“¹ Object Tracking App')

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
with st.sidebar:
    st.header("ğŸ“˜ About")
    st.markdown("""
    This app tracks moving objects in uploaded videos using background subtraction,  
    noise reduction, and contour detection.

    **Developed by:** *Mohamed Mostafa*
    """)
    st.divider()
    st.subheader("âš™ï¸ Settings")
    fps = st.slider("ğŸšï¸ Playback FPS", min_value=1, max_value=60, value=30)
    delay = 1 / fps
    min_area = st.slider("ğŸ” Minimum Object Area", min_value=50, max_value=1000, value=100, step=50)

# Ù„ÙˆÙ† Ø«Ø§Ø¨Øª Ù„Ù„Ù…Ø±Ø¨Ø¹Ø§Øª: Ø£Ø®Ø¶Ø±
box_color = (0, 255, 0)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
upload_vid = st.file_uploader('ğŸ“ Please upload a video file', type=['mp4', 'avi'])

if upload_vid is not None:
    # Ø­ÙØ¸ Ù…Ø¤Ù‚Øª Ù„Ù„ÙÙŠØ¯ÙŠÙˆ
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(upload_vid.read())

    # Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    capture = cv2.VideoCapture(tfile.name)
    total_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))

    # background subtractor
    back_subtractor = cv2.createBackgroundSubtractorMOG2(varThreshold=50, detectShadows=False)

    # Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ø¹Ø±Ø¶
    stframe1 = st.empty()
    stframe2 = st.empty()
    progress = st.progress(0)
    object_counter = st.empty()

    current_frame = 0

    # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§
    while capture.isOpened():
        ret, frame = capture.read()
        if not ret:
            break  # Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ

        frame = cv2.resize(frame, (640, 360))

        # ØªØ·Ø¨ÙŠÙ‚ Background Subtraction
        fg_mask = back_subtractor.apply(frame)
        img_blur = cv2.GaussianBlur(fg_mask, (11, 11), 0)
        _, img_thresh = cv2.threshold(img_blur, 200, 255, cv2.THRESH_BINARY)

        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
        img_morph = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel)
        img_morph = cv2.morphologyEx(img_morph, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(img_morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        object_count = 0

        for cnt in contours:
            if cv2.contourArea(cnt) > min_area:
                x, y, w, h = cv2.boundingRect(cnt)
                cv2.rectangle(frame, (x, y), (x + w, y + h), box_color, 2)
                object_count += 1

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        fg_mask_colored = cv2.applyColorMap(fg_mask, cv2.COLORMAP_BONE)

        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
        stframe1.image(frame_rgb, caption='ğŸ¥ Original Feed', channels='RGB')
        stframe2.image(fg_mask_colored, caption='ğŸ•µï¸â€â™‚ï¸ Foreground Mask', channels='BGR')
        object_counter.markdown(f"ğŸ”´ **Objects detected:** `{object_count}`")

        # ØªÙ‚Ø¯Ù… Ø§Ù„Ø´Ø±ÙŠØ·
        current_frame += 1
        progress.progress(min(current_frame / total_frames, 1.0))

        time.sleep(delay)

    capture.release()
else:
    st.info("ğŸ“Œ Please upload a video file to start.")
